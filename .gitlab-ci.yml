image: eicweb.phy.anl.gov:4567/eic/juggler/juggler:latest

workflow:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
    - if: '$CI_PIPELINE_SOURCE == "webide"'
    - if: '$CI_COMMIT_BRANCH == "master"'

variables:
  JOBS: 6

default:
  timeout: 3 hours
  artifacts:
    expire_in: 1 week 
    paths:
      - results/

stages:
  - nevents
  - timings
  - collect

.datasets:
  parallel:
    matrix:
      - DATA:
        - "DIS/NC/DIS_NC_5x41.csv"
        - "DIS/NC/DIS_NC_5x100.csv"
        - "DIS/NC/DIS_NC_10x100.csv"
        - "DIS/NC/DIS_NC_10x275.csv"
        - "DIS/NC/DIS_NC_18x275.csv"
        - "DIS/NC/DIS_NC_hepmc2.csv"
        - "DIS/CC/DIS_CC_hepmc2.csv"
        - "EXCLUSIVE/TCS/TCS_5x41.csv"
        - "EXCLUSIVE/TCS/TCS_5x100.csv"
        - "EXCLUSIVE/TCS/TCS_10x100.csv"
        - "EXCLUSIVE/TCS/TCS_18x275.csv"
        - "EXCLUSIVE/DVCS.csv"
        - "EXCLUSIVE/DEMP.csv"
        - "EXCLUSIVE/DVMP.csv"
        - "EXCLUSIVE/x_y_psi.csv"
        - "EXCLUSIVE/omega.csv"
        - "EXCLUSIVE/TCS/TCS_5x41.csv"
        - "EXCLUSIVE/TCS/TCS_5x100.csv"
        - "EXCLUSIVE/TCS/TCS_10x100.csv"
        - "EXCLUSIVE/TCS/TCS_18x275.csv"
        - "EXCLUSIVE/UPSILON.csv"
        - "SIDIS/Lambda.csv"
        - "SIDIS/ep_18x110.csv"
        - "SIDIS/eA_18x110.csv"
        - "SINGLE/SINGLE_3to50deg.csv"
        - "SINGLE/SINGLE_45to135deg.csv"
        - "SINGLE/SINGLE_130to177deg.csv"
        - "SR/SR.csv"

nevents:
  stage: nevents
  extends: .datasets
  script:
    - mc config host add S3 https://dtn01.sdcc.bnl.gov:9000 ${S3_ACCESS_KEY} ${S3_SECRET_KEY}
    - mkdir -p $(dirname results/datasets/nevents/$DATA)
    - cat $DATA | parallel -j $JOBS --colsep "," scripts/count_events.sh {1} {2} {3} | sort | tee results/datasets/nevents/$DATA

timing:
  stage: timings
  extends: .datasets
  needs: ["nevents"]
  script:
    - mc config host add S3 https://dtn01.sdcc.bnl.gov:9000 ${S3_ACCESS_KEY} ${S3_SECRET_KEY}
    - mkdir -p $(dirname results/datasets/timings/$DATA)
    - cat results/datasets/nevents/$DATA | parallel -j $JOBS --colsep "," scripts/determine_timing.sh {1} {2} {3} | sort | tee results/datasets/timings/$DATA

collect:
  stage: collect
  needs: ["timing"]
  script:
    - rm -rf results/logs/
    - ls -Rlh results/datasets/
