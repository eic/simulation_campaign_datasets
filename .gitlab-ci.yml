variables:
  CONTAINER_NAME: "eic_ci"
  IMAGE_TAG: "nightly"
  DETECTOR_CONFIG: "epic_craterlake"
  DETECTOR_VERSION: "main"
  EBEAM: "18"
  PBEAM: "275"
  NEVENTS_PER_TEST: "100"

image: eicweb.phy.anl.gov:4567/containers/eic_container/${CONTAINER_NAME}:${IMAGE_TAG}

default:
  timeout: 3 hours
  artifacts:
    expire_in: 1 week
    paths:
      - results/
  before_script:
    - shopt -s expand_aliases
    - alias parallel='parallel -k --lb -j 1 --colsep ","'

stages:
  - nevents
  - timings
  - collect

.nevents:
  stage: nevents
  script:
    - export DETECTOR_CONFIG="${DETECTOR_CONFIG_OVERRIDE:-${DETECTOR_CONFIG}}"
    - export DETECTOR_VERSION="${DETECTOR_VERSION_OVERRIDE:-${DETECTOR_VERSION}}"
    - export RESULTS_BASE="results/${CONTAINER_NAME}/${IMAGE_TAG}/${DETECTOR_CONFIG}/${DETECTOR_VERSION}"
    - echo "INFO [nevents] - CONTAINER_NAME = ${CONTAINER_NAME}"
    - echo "INFO [nevents] - IMAGE_TAG = ${IMAGE_TAG}"
    - echo "INFO [nevents] - DETECTOR_CONFIG = ${DETECTOR_CONFIG}"
    - echo "INFO [nevents] - DETECTOR_VERSION = ${DETECTOR_VERSION}"
    - echo "INFO [nevents] - RESULTS_BASE = ${RESULTS_BASE}"
    - mkdir -p $(dirname ${RESULTS_BASE}/datasets/glob/$DATA)
    - grep -v "^\#" $DATA | parallel scripts/glob.sh ${RESULTS_BASE}/datasets/glob/$DATA {}
    - sort -o ${RESULTS_BASE}/datasets/glob/$DATA ${RESULTS_BASE}/datasets/glob/$DATA
    - mkdir -p $(dirname ${RESULTS_BASE}/datasets/nevents/$DATA)
    - grep -v "^\#" ${RESULTS_BASE}/datasets/glob/$DATA | parallel scripts/count_events.sh ${RESULTS_BASE}/datasets/nevents/$DATA {}
    - sort -o ${RESULTS_BASE}/datasets/nevents/$DATA ${RESULTS_BASE}/datasets/nevents/$DATA
    - sort -o $DATA $DATA

.timings:
  stage: timings
  script:
    - export DETECTOR_CONFIG="${DETECTOR_CONFIG_OVERRIDE:-${DETECTOR_CONFIG}}"
    - export DETECTOR_VERSION="${DETECTOR_VERSION_OVERRIDE:-${DETECTOR_VERSION}}"
    - export EBEAM="${EBEAM_OVERRIDE:-${EBEAM}}"
    - export PBEAM="${PBEAM_OVERRIDE:-${PBEAM}}"
    - export NEVENTS_PER_TEST="${NEVENTS_PER_TEST_OVERRIDE:-${NEVENTS_PER_TEST}}"
    - export RESULTS_BASE="results/${CONTAINER_NAME}/${IMAGE_TAG}/${DETECTOR_CONFIG}/${DETECTOR_VERSION}"
    - echo "INFO [timings] - CONTAINER_NAME = ${CONTAINER_NAME}"
    - echo "INFO [timings] - IMAGE_TAG = ${IMAGE_TAG}"
    - echo "INFO [timings] - DETECTOR_CONFIG = ${DETECTOR_CONFIG}"
    - echo "INFO [timings] - DETECTOR_VERSION = ${DETECTOR_VERSION}"
    - echo "INFO [timings] - EBEAM = ${EBEAM}"
    - echo "INFO [timings] - PBEAM = ${PBEAM}"
    - echo "INFO [timings] - NEVENTS_PER_TEST = ${NEVENTS_PER_TEST}"
    - echo "INFO [timings] - RESULTS_BASE = ${RESULTS_BASE}"
    - mkdir -p $(dirname ${RESULTS_BASE}/datasets/timings/$DATA)
    # Use sed '1!d1' instead of head -n 1 to avoid pipefail issues
    - grep -v "^\#" ${RESULTS_BASE}/datasets/nevents/$DATA | sed '1!d' | parallel scripts/determine_timing.sh ${RESULTS_BASE}/datasets/timings/$DATA {}
    - |
      IFS="," read file ext nevents dt0 dt1 < ${RESULTS_BASE}/datasets/timings/$DATA
      export dt0 dt1
      grep -v "^\#" ${RESULTS_BASE}/datasets/nevents/$DATA | sed '1d' | parallel scripts/determine_timing.sh ${RESULTS_BASE}/datasets/timings/$DATA {}
    - sort -o ${RESULTS_BASE}/datasets/timings/$DATA ${RESULTS_BASE}/datasets/timings/$DATA

.timings_all:
  stage: timings
  script:
    - export RESULTS_BASE="results/${CONTAINER_NAME}/${IMAGE_TAG}/${DETECTOR_CONFIG}/${DETECTOR_VERSION}"
    - mkdir -p $(dirname ${RESULTS_BASE}/datasets/timings/$DATA)
    - grep -v "^\#" ${RESULTS_BASE}/datasets/nevents/$DATA | parallel scripts/determine_timing.sh ${RESULTS_BASE}/datasets/timings/$DATA {}
    - sort -o ${RESULTS_BASE}/datasets/timings/$DATA ${RESULTS_BASE}/datasets/timings/$DATA

.collect:
  stage: collect
  script:
    - export RESULTS_BASE="results/${CONTAINER_NAME}/${IMAGE_TAG}/${DETECTOR_CONFIG}/${DETECTOR_VERSION}"
    - rm -rf results/logs/
    - find ${RESULTS_BASE}/datasets/
    - find ${RESULTS_BASE}/datasets/timings/ -name "*.csv" -print0 -exec awk 'BEGIN {FS=","} {sum+=$3*$5+$4} END {print(":",sum/3600,"core-hours")}' {} \;
    - for d in `find ${RESULTS_BASE}/datasets/timings/ -type d` ; do
        echo -n $d ;
        find $d -name "*.csv" -exec cat {} \; | awk 'BEGIN {FS=","} {sum+=$3*$5+$4} END {print(":",sum/3600,"core-hours")}' ;
      done
    - find ${RESULTS_BASE}/datasets/timings/ -name "*.csv" -print0 -exec awk 'BEGIN {FS=","} {sum+=$3*$7+$6} END {print(":",sum/1048576,"GB (full)")}' {} \;
    - for d in `find ${RESULTS_BASE}/datasets/timings/ -type d` ; do
        echo -n $d ;
        find $d -name "*.csv" -exec cat {} \; | awk 'BEGIN {FS=","} {sum+=$3*$7+$6} END {print(":",sum/1048576,"GB (full)")}' ;
      done
    - find ${RESULTS_BASE}/datasets/timings/ -name "*.csv" -print0 -exec awk 'BEGIN {FS=","} {sum+=$3*$9+$8} END {print(":",sum/1048576,"GB (reco)")}' {} \;
    - for d in `find ${RESULTS_BASE}/datasets/timings/ -type d` ; do
        echo -n $d ;
        find $d -name "*.csv" -exec cat {} \; | awk 'BEGIN {FS=","} {sum+=$3*$9+$8} END {print(":",sum/1048576,"GB (reco)")}' ;
      done

include:
  - local: 'BACKGROUNDS/config.yml'
  - local: 'DIS/config.yml'
  - local: 'EXCLUSIVE/config.yml'
  - local: 'SIDIS/config.yml'
  - local: 'SINGLE/config.yml'
#  - local: 'SR/config.yml'

collect:
  extends: .collect
  needs:
    - "BACKGROUNDS:collect"
    - "DIS:collect"
    - "EXCLUSIVE:collect"
    - "SIDIS:collect"
    - "SINGLE:collect"
#    - "SR:collect"